---
title: Electronic Resource Reporting - Transform
author: Andy Meyer
date: '2017-10-23'
slug: electronic-resource-reporting-transform
categories:
  - Electronic Resources
tags:
  - tidy
  - tidyverse
  - transform
---

After getting the usage data and financial information into R and into a tidy data format, my next step was to transform this data. So far, the transformations are limited to filtering, summarizing, and graphing the data. But there are many other transformations that could be considered or added.

Like the other steps, I've adopted a functional approach to handle these transformations. All of the functions described here perform transformations on the same dataframe - the database usage statistics in the tidy format - without ever changing or updating that dataframe.

## Filtering Usage

Filtering is probably the easiest transformation to understand. Here is the code for a simple function with descriptions.
```{r echo=TRUE}
usage.select.database <- function(DatabaseName,
                                  StartYear,
                                  EndYear,
                                  Action = all.actions){
  DB1 %>%
    filter(Database %in% DatabaseName) %>%
    filter(Date >= StartYear, Date <= EndYear) %>%
    filter(User_Activity %in% Action) %>%
    spread(Date,Usage) %>%
    write_csv(paste(output.folder, "usage.table.1.csv",sep="/")) %>%
    return()
}
```
My function name is r``` usage.select.database ``` - this isn't the best name but I found naming functions to be the most difficult part of the process! This function accepts four parameters and then returns only the relevant usage information.

The parameters:

* ```DatabaseName``` - specifies the database name; right now this must match exactly the name as specified in the Counter Reports.
* ```StartYear``` and ```EndYear``` - takes numerical values that specify the year. This function currently is not sophisticated enough to accept more complicated data parameters (like June 2014 to June 2015) but might be able to in the future.
* ```Action``` - this is an optional parameter that allows the function to filter for a particular User Activity from the Usage Reports. I wanted to make this parameter optional so I supplied the default value of ```all.actions```. This variable was defined earlier - here is the definition ```all.actions <- unique(DB1$User_Activity)``` and while it is not necesary I found it easier to use a varialbe here.

Looking now to the lines in the function, they are very straightforward. The first line filters on the database name, the second line imposes the data limits, and the third line focuses on a particular usage action. Because the original dataframe was tidy, the filter function works wonderfully and the code is very human readable.

However, to make the results more readable to a human, the fourth line 'spreads' the data into a more readable format. The ```spread``` function makes the long (tidy) data into a wider (untidy) format that is somewhat easier to read...or at least more closely approximates the original counter report. After writing this data to a CSV file, this function returns the filtered data in a tabular form.

This function is extremely basic but the general structure of the function as well as the function's parameters form a common structure that makes other functions more readable.

## Graphing Usage

The next transformation does the same filtering but the output is a simple line graph instead of the raw data. Here is the code for that function:

```{r echo=TRUE}
usage.graph.database <- function(DatabaseName,
                                 StartYear,
                                 EndYear,
                                 Action = all.actions){
  DB1 %>%
    filter(Database %in% DatabaseName) %>%
    filter(Date >= StartYear, Date <= EndYear) %>%
    filter(User_Activity %in% Action) %>%
    ggplot(aes(Date, Usage)) +
    geom_line() +
    geom_smooth(span=0.7) +
    scale_x_yearmon() +
    facet_grid(User_Activity ~ ., scales = "free")
}
```

Again, the four parameters and the first few lines are the same as before. However, instead of returning the data itself, this function uses the ````ggplot``` package to create a graph. The ```ggplot``` package is a very powerful graphics package that can create publication quality graphs. There is a some learning curve to this package and approach, but overall creating a simple line graph like this was relatively straigtforward.

Looking at those lines in detail:

* ```ggplot(aes(Date, Usage))``` - this creates the plot area and specifies the aesthetics that I want to use. Here I'm using Date (on the x axis) and Usage (on the y axis). I'm applying these aesthetics here because I want them to apply for the whole graph.
* ```geom_line()``` - this adds a layer for a line graph to this plot.
* ```geom_smooth(span=0.7) ``` - this adds a layer for a 'smoother'. This helps the graph convey visually the trends that might be otherwise obscured by the great level of variation.
* ```scale_x_yearmon()``` - this specifies that the scale of the x axis is yearmon. This function is from the ```zoo``` package.
* ```facet_grid(User_Activity ~ ., scales = "free")``` - this creates facets which divide the plot into subplots based on the ```User_Activity``` variable. It also specifies that the scales are free because the total usage varies widely based on the different User Actions.

## Summarizing Usage

The last function I'm going to dissect in this post is awkwardly called ```usage.graph.database.acad.term ```. This function filters usage data based on parameters, mutates the date information to group on academic term, and then returns either the raw data or a graph of the data. Here is the function:

```{r echo=TRUE}
# Graphs database usage based on academic term.
usage.graph.database.acad.term <- function(DatabaseName,StartYear,EndYear,Action = all.actions){
  DB1 %>%
    filter(Database %in% DatabaseName) %>%
    filter(Date >= StartYear, Date <= EndYear) %>%
    filter(User_Activity %in% Action) %>%
    mutate(Year = year(Date), Month=month(Date)) %>%
    mutate(Academic_Term = derivedFactor(
      "Spring" = (Month==1 | Month==2  | Month==3  | Month==4),
      "Summer" = (Month==5 | Month==6  | Month==7  | Month==8),
      "Fall"   = (Month==9 | Month==10 | Month==11 | Month==12)
    )) %>%
    group_by(Database,User_Activity,Academic_Term,Year) %>%
    summarize(Usage=sum(Usage)) %>%
    ggplot(aes(x = Academic_Term, y = Usage)) +
    geom_bar(aes(fill=factor(Year)),
             stat="identity",
             position = position_dodge()) +
    scale_fill_discrete(name="Year") +
    xlab("Academic Term") +
    ylab("Usage")
}
```

Again, the parameters and filtering steps are the same and return only the data we are interested in exploring.

The ```mutate``` lines create new variables from existing data points. ```mutate(Year = year(Date), Month=month(Date)) ``` creates new columns for Year and Month that get the information from the data field. The next chunk adds a new field that derives the academic term from the month. This isn't perfect... but it labels the months of January-April as "Spring", May-August as "Summer", and September-December as "Fall." The function ```derivedFactor``` is from the ```mosaic``` package.

At this point, our data is still tidy but there are additional columns of information containing the Year, Month, and Academic Term. The funciton then groups by Database, User Activity, Academic Term, and Year and then summarizes usage. At this point the data could be spread back to a wider format or graphed in a variety of ways.

This function creates a bar graph of the data with Academic Term on the x axis and Usage on the y axis. The usage is grouped by academic term and color reflects the year. This representation makes it easier to see changes over time by removing some of the variability within the dataset and displaying the information in new ways.

## Conclusion
These transformation all provide useful insight into the data and make it more useable and understandable. I've worked to keep these functions as abstract as possible in an effort to make them reproducible for many different databases, date ranges, and user actions. This allows for easy exploration and to see new patterns. However, the limitation of this approach is that none of the graphs are particularly good at communicating a particular point or story; it might be worth customizing a graph to tell a particular story or convey a particular point to a specific audience.




